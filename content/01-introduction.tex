\chapter{Einleitung}
Im Gesundheitswesen bilden sich große Mengen an Daten durch die Digitalisierung der Behandlungen. Solche Massendaten bergen ein enormes Potential für wissenschaftliche Erkenntnisgewinne. Mit den modernsten Methoden wie \gls{ml} können aus diesen Daten Muster und Erkenntnisse extrahiert werden, sodass mit deren Hilfe zukünftige Behandlungen effizienter und kostengünstiger gestaltet zu können. Mit der Einführung der elektronischen Patientenakte (\gls{ePa}) in Deutschland durch die Regierung erhält jeder Krankenversicherte eine \gls{ePa}, die die vollständige Dokumentation der medizinischen Behandlungshistorie umfasst. In der aktuellen Corona Pandemie entstehen große Datenmengen beispielsweise über den Krankheitsverlauf eines infizierten Menschen. Darin sind sensible Informationen, die in einem direkten Bezug zu einer Person stehen, enthalten. Diese personenbezogenen Gesundheitsdaten stehen durch Art. 9 Abs. 1 der \gls{dsgvo} unter besonderem Schutz und sind damit nur in explizit ausgeschriebenen Ausnahmefällen zu verarbeiten wie dies im darauffolgenden Absatz weiter erklärt. Sie können durch eine Einwilligung des Patienten für die Datenverarbeitung genutzt werden. Um die Verarbeitung von Gesundheitsdaten für wissenschaftliche Zwecke auch ohne vorliegenden Ausnahmefall zu ermöglichen, können die Daten vor einer solchen Verarbeitung anonymisiert bzw. pseudonymisiert werden. Der Erwägungsgrund 26 im \gls{dsgvo} fordert dafür, dass das Risiko der Re-Identifikation durch einen Angreifer mit seinem benötigten Zeitaufwand und technologischen Möglichkeiten eingeschätzt werden soll. Wenn das Risiko gering genug ist, dürfen anonymisierte bzw. pseudonymisierte Daten veröffentlicht werden.


Dass eine solche Re-Identifikation bei unzureichenden Sicherheitsmaßnahmen grundsätzlich möglich sein kann zeigt ein Beispiel aus dem Jahr 2008, bei dem Netflix \parencite{NetflixDataset} einen Wettbewerb ausgerufen hat, beim dem die Treffsicherheit des Algorithmus der Software für die Empfehlung eines Filmes für den Kunden verbessert werden sollte. Zu diesem Zweck hat Netflix eine Datenbasis für die Berechnungen des Algorithmus mit 100 Millionen anonymisierten Datensätze veröffentlicht. Sie hat aus den Informationen des Nutzernamens, des Filmtitels, der Bewertung des Nutzers für den jeweiligen Film und des Datums der Bewertung bestanden. Der Nutzername ist durch ein Pseudonym ersetzt worden, somit pseudonymisiert. Trotz dessen ist es zwei Wissenschaftlern durch eine statistische de-anonymisierende Attacke gelungen, Nutzer von Netflix zu re-identifizieren. Sie haben das Filmbewertungssystem \enquote{Internet Movie Database} genutzt, bei dem einige angemeldeten Nutzern echte Namen enthalten hatten und haben sie mit den Datensätze von Netflix verglichen. Ihnen ist eine partielle De-Anonymisierung der Netflix Daten gelungen, obwohl sie ursprünglich pseudonymisiert gewesen sind.


Für die Pseudonymisierung der Daten haben die Netflix Betreiber das Verfahren \textit{k-anonymity} verwendet, welches limitiert und nicht aussagekräftig in seiner Schutzgarantie ist.
Auf dieses Verfahren sind Erweiterungen wie \textit{l-diversity} \parencite{L-Diversity} und \textit{t-closeness} \parencite{T-Closeness} gefolgt, welche mit weiteren Bedingungen die Schwachstellen des zu vorherigen Verfahrens abdecken sollten. Trotz dieser Versuche ist das hohe Risiko der Re-Identifizierung erhalten geblieben.


Dagegen stellt das Konzept \textit{Differential Privacy} von  Cynthia Dwork \parencite{Dwork2006} eine mathematische Definition vor, wodurch eine Abwägung zwischen Nutzbarkeit und Privatisierung der Daten möglich ist. In einer Datenbank wird den Daten \enquote{mathematisches Rauschen} hinzugefügt, welches dann von den Originaldaten ununterscheidbar ist, um Rückschlüsse zu verhindern. Die verrauschten Daten beeinflussen jedoch statistische Zusammenhänge nicht, da sonst die Nutzbarkeit der Daten für eine Auswertung verfällt. Das Verfahren Differential Privacy (\gls{dp}) setzt den Parameter $\epsilon$ ein, welcher als ein Maß zwischen der Nutzbarkeit und dem Risiko der Re-Identifizierung dient.


Der United States Census \parencite{USC} verwendet das Verfahren \gls{dp} für die Volkszählung in den USA. Seit der Volkszählung 2020 wird es eingesetzt, sodass viele Bedrohungen durch die digitale Welt verhindert werden konnten. Bei der Veröffentlichung der Statistiken über die Bevölkerung konnten durch das mathematische Rauschen Angaben über die Herkunft, Einkünfte usw., ohne ein hohes Risiko in Kauf zu nehmen, preisgegeben werden. Damit ist zum ersten Mal \gls{dp} für eine weitreichende Aufgabe erfolgreich von der Bundesbehörde eingesetzt worden.


Zur gleichen Zeit ist das Interesse für dieses Verfahren ebenfalls in den High-Tech Firmen aufgekommen. Microsoft, IBM \gls{dp} und Google \gls{dp} haben auf dieser mathematischen Definition Frameworks entwickelt, welche das verrauschte Auswerten von Daten ermöglichen. Die Daten werden durch Mechanismen mit Rauschen versehen und anschließend stehen statische Methoden für die Auswertung zur Verfügung. Die Frameworks der Konzerne verwenden dieselben Mechanismen für das Erzeugen des mathematischen Rauschens und erfüllen denselben Zweck, die Privatisierung von sensiblen Daten mit hoher Nutzbarkeit. 

In Rahmen dieser Bachelorarbeit wird der Fragestellung nachgegangen, inwieweit das Verfahren \gls{dp} durch Frameworks für die Privatisierung von personenbezogenen medizinischen Daten eingesetzt werden kann. Diese Frameworks stammen von den drei zuvor genannten Konzernen. Im Gesundheitssystem sammeln sich große Datenbeständen wie z.B. durch die aktuelle COVID-19 Pandemie, die als Datenquelle für diese Frameworks genutzt werden können. Solch ein \gls{dp} Verfahren muss das Risiko der Re-Identifikation minimal und messbar halten, damit bei der Veröffentlichung der privatisierten Daten keine Rückschlüsse durch zusätzliche Quellen erfolgen kann. Bisher sind in keinen weiteren Evaluationen Frameworks von der Industrie zur Nutzung der Privatisierung untersucht worden. Die Herausforderung liegt darin, die Nutzbarkeit der verrauschten Daten für die Forschung zu bewahren, ohne ein nicht-vernachlässigbares Risiko für eine Re-Identifizierung einzugehen.

\section{Ziel der Arbeit}
In dieser Arbeit wird eine generische Schnittstelle zur Evaluation von medizinischen Daten implementiert. Sie wird in einem medizinischen Anwendungsfall eingesetzt. Für die Evaluation sind die Gesundheitsdaten aus der Veröffentlichung der Anzahl an COVID-19 infizierten Menschen im Zeitraum Dezember des Jahres 2021 genutzt worden. Jedes Framework erhält diese Daten als Eingabe und wertet sie durch eine \gls{dp} Funktion aus. Aufgrund ihrer jeweiligen Berechnungsergebnisse werden die Frameworks anhand Metriken bewertet. Sie umfassen die Kategorien: die Einhaltung der Privatsphäre, der Genauigkeit und der Erwartungstreue.

Wenn die Werte der Metriken den Erwartungen entsprechen, können die Frameworks in den jeweiligen Kategorien eingesetzt werden. Liefert ein Framework ungenaue oder unerwartete Werte, so fließt dies negativ in dessen Bewertung ein.

Die gewonnen Erkenntnisse sollen über die Einsetzbarkeit der Frameworks für die Privatisierung von medizinischen Daten Aufschluss geben.
\section{Struktur dieser Arbeit}
In Kapitel 2 werden die wichtigsten theoretischen Konzepte als Grundlage für \gls{dp} vermittelt. Insbesondere wird dabei die Definition des mathematischen Rauschens und die Auswertung der Evaluation durch die Metriken nachvollziehen zu können, eingeführt. Des Weiteren folgt im gleichen Kapitel eine strukturierte Übersicht der Funktionalitäten der Frameworks.
Anschließend folgen verwandte Arbeiten in Kapitel 3, bei den die Evaluation von \gls{dp} durch mathematische Metriken erfolgt ist und über Erkenntnisse der Einhaltung der Definition besprochen worden sind. Hierbei spielt der Einsatzbereich des Gesundheitswesen sowie die benutzten Methoden zur Auswertung der Genauigkeit und Privatisierung eine wichtige Rolle
Auf die verwandten Arbeiten folgt die Praxis, in der die Einsetzbarkeit der Frameworks in einem medizinischen Anwendungsfall realisiert wird (im Kapitel 4). In diesem dient die \gls{ePa} als medizinische Datenbasis, um eine mögliche Anwendung der Frameworks in der Realität aufzuzeigen. In Kapitel 5 wird dieser Anwendungsfall durch die Implementierung der Arbeit, eine generische Schnittstelle, erweitert. Sie dient zur Berechnung der verrauschten Daten sowie Evaluation dieser.
In Kapitel 6 folgt der Kern dieser Arbeit, und zwar die Evaluation der Ergebnisse bzgl. der Metriken. Dabei sind die metrischen Werte jeweils für jedes Framework berechnet und miteinander verglichen worden.
Die daraus gewonnen Ergebnisse werden in Kapitel 7 bezüglich der Einsetzbarkeit, Nutzbarkeit und des Schutzes von \gls{dp} bewertet. Schlussendlich folgt in Kapitel 8 ein Fazit der gesamten Arbeit und ein Ausblick auf zukünftige Arbeiten.
